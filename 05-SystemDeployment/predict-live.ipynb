{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad037c51",
   "metadata": {},
   "source": [
    "# Model deployment\n",
    "In this laboratory, the objective is to convert a DDoS dection script written for Jupyter notebook into a stand-alone Python program that can be deployed to the target machine. To use this notebeook, first train and save an MLP model with the script of laboratory [03-Hyperparameters](https://github.com/doriguzzi/dl-for-network-security-phd/tree/main/03-Hyperparameters), and then test your model using this script on live traffic or on a network traffic trace locally available on your computer.\n",
    "If everything works as expected, convert this notebook into a Python script that supports the following command-line arguments:\n",
    "- Path of the MLP model\n",
    "- Path of the ingress network interface (alternatively, the path to a network traffic trace) \n",
    "- Path to the output CSV file where the program writes the classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aec2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Roberto Doriguzzi-Corin\n",
    "# Project: Lecture on Intrusion Detection with Deep Learning\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\n",
    "import random as rn\n",
    "import h5py\n",
    "import glob\n",
    "import time\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "import logging\n",
    "import pprint\n",
    "import nest_asyncio\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score,confusion_matrix\n",
    "from traffic_processing import *\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "# Seed Random Numbers\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "config = tf.compat.v1.ConfigProto(inter_op_parallelism_threads=1)\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3858ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results(Y_true, Y_pred,packets, model_name, data_source, prediction_time,writer):\n",
    "    ddos_rate = '{:04.3f}'.format(sum(Y_pred)/Y_pred.shape[0])\n",
    "\n",
    "    if Y_true is not None: # if we have the labels, we can compute the classification accuracy\n",
    "        Y_true = Y_true.reshape((Y_true.shape[0], 1))\n",
    "        accuracy = accuracy_score(Y_true, Y_pred)\n",
    "\n",
    "        f1 = f1_score(Y_true, Y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(Y_true, Y_pred,labels=[0,1]).ravel()\n",
    "        tnr = tn / (tn + fp)\n",
    "        fpr = fp / (fp + tn)\n",
    "        fnr = fn / (fn + tp)\n",
    "        tpr = tp / (tp + fn)\n",
    "\n",
    "        row = {'Model': model_name, 'Time': '{:04.3f}'.format(prediction_time), 'Packets': packets,\n",
    "               'Samples': Y_pred.shape[0], 'DDOS%':ddos_rate,'Accuracy':accuracy, 'F1Score':f1,\n",
    "               'TPR':tpr, 'FPR':fpr, 'TNR':tnr, 'FNR':fnr, 'Source':data_source}\n",
    "    else:\n",
    "        row = {'Model': model_name, 'Time': '{:04.3f}'.format(prediction_time), 'Packets': packets,\n",
    "               'Samples': Y_pred.shape[0], 'DDOS%': ddos_rate, 'Accuracy': \"N/A\", 'F1Score': \"N/A\",\n",
    "               'TPR': \"N/A\", 'FPR': \"N/A\", 'TNR': \"N/A\", 'FNR': \"N/A\", 'Source': data_source}\n",
    "    pprint.pprint(row,sort_dicts=False)\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7cf89e",
   "metadata": {},
   "source": [
    "## External files\n",
    "In the cell below, you need to set the right path to your MLP model. The path to the pcap file is already set. In this script, you can also find the code to collect network traffic from one of the network interfaces of the target computer. In the example below, the name of the interface is ```eth0```, however it might not be the right name on the target computer. \n",
    "\n",
    "Note that, the stand-alone Python program must take the paths (or the interface name) as command-line arguments, therefore the code in the following cell must be modified accordingly (e.g., using [argparse](https://docs.python.org/3/library/argparse.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be8d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"/path/to/the/mlp-model\")\n",
    "print (model.summary())\n",
    "pcap_file = \"../Datasets/IDS2017/IDS2017-dataset.pcap\"\n",
    "cap = pyshark.FileCapture(pcap_file)\n",
    "data_source = pcap_file.split('/')[-1].strip()\n",
    "#cap =  pyshark.LiveCapture(interface=\"eth0\")\n",
    "#data_source = \"eth0\"\n",
    "\n",
    "print (\"Traffic source: \",data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849e3ead",
   "metadata": {},
   "source": [
    "## Log file\n",
    "In the stand-alone Python script, the path to the output log file must be specified as a command-line argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_fieldnames = ['Model','Time','Packets', 'Samples', 'DDOS%','Accuracy', 'F1Score','TPR','FPR','TNR','FNR','Source']\n",
    "predict_file = open('./results.csv', 'a', newline='')\n",
    "predict_file.truncate(0)  # clean the file content (as we open the file in append mode)\n",
    "predict_writer = csv.DictWriter(predict_file, fieldnames=classify_fieldnames)\n",
    "predict_writer.writeheader()\n",
    "predict_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8349a7",
   "metadata": {},
   "outputs": [],
   "source": [
    " # load the labels, if available\n",
    "labels = parse_labels(\"DOS2017\")\n",
    "time_window = 10\n",
    "max_flow_len = 10\n",
    "mins, maxs = static_min_max(time_window)\n",
    "\n",
    "while (True):\n",
    "    samples = process_live_traffic(cap,labels, max_flow_len, traffic_type=\"all\", time_window=time_window)\n",
    "    if len(samples) > 0:\n",
    "        X,Y_true,keys = dataset_to_list_of_fragments(samples)\n",
    "        X = np.array(normalize_and_padding(X, mins, maxs, max_flow_len))\n",
    "        if labels is not None:\n",
    "            Y_true = np.array(Y_true)\n",
    "        else:\n",
    "            Y_true = None\n",
    "\n",
    "        X = np.expand_dims(X, axis=3)\n",
    "        pt0 = time.time()\n",
    "        Y_pred = np.squeeze(model.predict(X, batch_size=2048) > 0.5,axis=1)\n",
    "        pt1 = time.time()\n",
    "        prediction_time = pt1 - pt0\n",
    "            \n",
    "        try:\n",
    "            [packets] = count_packets_in_dataset([X])\n",
    "            report_results(np.squeeze(Y_true), Y_pred, packets, model.name, data_source, prediction_time,predict_writer)\n",
    "            predict_file.flush()\n",
    "        except:\n",
    "            print(\"No packets received during the last time window.\")\n",
    "\n",
    "predict_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
