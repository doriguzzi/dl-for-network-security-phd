{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "093f8861",
   "metadata": {},
   "source": [
    "# System deployment\n",
    "In this laboratory, the objective is to convert a DDoS dection script written for Jupyter notebook into a stand-alone Python program that can be deployed to the target machine. To use this notebeook, first train and save an ANN model with the script of laboratory [03-Hyperparameters](https://github.com/doriguzzi/dl-for-network-security-phd/tree/main/03-Hyperparameters), and then test your model using this script.\n",
    "If everything works as expected, convert this notebook into a Python script that supports the following command-line arguments:\n",
    "- Path to the ANN model\n",
    "- Path to the test set\n",
    "- Path to the output CSV file where the program writes the classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99aec2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Roberto Doriguzzi-Corin\n",
    "# Project: Lecture on Intrusion Detection with Deep Learning\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import random as rn\n",
    "import h5py\n",
    "import glob\n",
    "import time\n",
    "import sys\n",
    "import csv\n",
    "import os\n",
    "import logging\n",
    "import pprint\n",
    "from sklearn.metrics import f1_score, accuracy_score,confusion_matrix\n",
    "from util_functions import *\n",
    "from traffic_processing import *\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "SEED=1\n",
    "\n",
    "# Seed Random Numbers\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "config = tf.compat.v1.ConfigProto(inter_op_parallelism_threads=1)\n",
    "\n",
    "FIELDNAMES = ['Model','Time','Packets', 'Samples', 'DDOS%','Accuracy', 'F1Score','TPR','FPR','TNR','FNR','Source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3858ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results(Y_true, Y_pred,packets, model_name, data_source, prediction_time,writer):\n",
    "    ddos_rate = '{:04.3f}'.format(sum(Y_pred)/Y_pred.shape[0])\n",
    "\n",
    "    if Y_true is not None: # if we have the labels, we can compute the classification accuracy\n",
    "        Y_true = Y_true.reshape((Y_true.shape[0], 1))\n",
    "        accuracy = accuracy_score(Y_true, Y_pred)\n",
    "\n",
    "        f1 = f1_score(Y_true, Y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(Y_true, Y_pred,labels=[0,1]).ravel()\n",
    "        tnr = tn / (tn + fp)\n",
    "        fpr = fp / (fp + tn)\n",
    "        fnr = fn / (fn + tp)\n",
    "        tpr = tp / (tp + fn)\n",
    "\n",
    "        row = {'Model': model_name, 'Time': '{:04.3f}'.format(prediction_time), 'Packets': packets,\n",
    "               'Samples': Y_pred.shape[0], 'DDOS%':ddos_rate,'Accuracy':accuracy, 'F1Score':f1,\n",
    "               'TPR':tpr, 'FPR':fpr, 'TNR':tnr, 'FNR':fnr, 'Source':data_source}\n",
    "    else:\n",
    "        row = {'Model': model_name, 'Time': '{:04.3f}'.format(prediction_time), 'Packets': packets,\n",
    "               'Samples': Y_pred.shape[0], 'DDOS%': ddos_rate, 'Accuracy': \"N/A\", 'F1Score': \"N/A\",\n",
    "               'TPR': \"N/A\", 'FPR': \"N/A\", 'TNR': \"N/A\", 'FNR': \"N/A\", 'Source': data_source}\n",
    "    pprint.pprint(row,sort_dicts=False)\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921fc0fd",
   "metadata": {},
   "source": [
    "## External files\n",
    "In the cell below, you need to set the right path to your ANN model. The path to the dataset is already set. However, the stand-alone Python program must take the two paths as command-line arguments, therefore the code in the following cell must be modified accordingly (e.g., using [argparse](https://docs.python.org/3/library/argparse.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be8d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"/path/to/the/mlp-model\")\n",
    "print (model.summary())\n",
    "testset = \"../Datasets/IDS2017/10t-10n-IDS2017-dataset-test.hdf5\" # test set\n",
    "X, Y = load_dataset(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfad98d",
   "metadata": {},
   "source": [
    "## Log file\n",
    "In the stand-alone Python script, the path to the output log file must be specified as a command-line argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_file = open('./results.csv', 'a', newline='')\n",
    "predict_file.truncate(0)  # clean the file content (as we open the file in append mode)\n",
    "predict_writer = csv.DictWriter(predict_file, fieldnames=FIELDNAMES)\n",
    "predict_writer.writeheader()\n",
    "predict_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8349a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "\n",
    "filename = testset.split('/')[-1].strip()\n",
    "[packets] = count_packets_in_dataset([X])\n",
    "\n",
    "Y_pred = None\n",
    "Y_true = Y\n",
    "avg_time = 0\n",
    "for iteration in range(iterations):\n",
    "    pt0 = time.time()\n",
    "    Y_pred = np.squeeze(model.predict(X, batch_size=2048) > 0.5)\n",
    "    pt1 = time.time()\n",
    "    avg_time += pt1 - pt0\n",
    "\n",
    "avg_time = avg_time / iterations\n",
    "\n",
    "try:\n",
    "    report_results(np.squeeze(Y_true), Y_pred, packets, model.name, filename, avg_time,predict_writer)\n",
    "    predict_file.flush()\n",
    "except:\n",
    "    print(\"No packets received during the last time window.\")\n",
    "\n",
    "predict_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
