{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e181315",
   "metadata": {},
   "source": [
    "# Evasion attack against a DL-based Intrusion Detection System\n",
    "In this laboratory, you will train a neural network on a dataset of benign and DDoS attack network traffic.\n",
    "Once the training process is completed, you will test the resulting model on unseen test data to evaluate the performance of the model on benign and malicious data. \n",
    "\n",
    "The model will be then tested on test data which has been artificially perturbed by adding some Gaussian noise to one of the features of the attack samples. The drop in some of the accuracy metric will demonstrate how an attacker can evade an ML-based IDS by conveniently crafting the attack traffic features. \n",
    "\n",
    "One approach to increase the robustness of the model to this type of attacks is called Adversarial Training, which consists on training the model with adversarial samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61b20e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Roberto Doriguzzi-Corin\n",
    "# Project: Lecture on Intrusion Detection with Deep Learning\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import copy\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import pprint\n",
    "import argparse\n",
    "\n",
    "import keras.callbacks\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import os\n",
    "import csv\n",
    "import h5py\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Seed Random Numbers\n",
    "SEED = 1\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "np.random.seed(SEED)\n",
    "rn.seed(SEED)\n",
    "config = tf.compat.v1.ConfigProto(inter_op_parallelism_threads=1)\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense,  Flatten, Conv2D, Reshape, Input, UpSampling2D\n",
    "from tensorflow.keras.layers import  MaxPooling2D, GlobalMaxPooling2D, Activation\n",
    "from tensorflow.keras.models import Model, Sequential, save_model, load_model, clone_model\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from scipy.stats import *\n",
    "from numpy.random import randint, normal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "tf.random.set_seed(SEED)\n",
    "K.set_image_data_format('channels_last')\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "#config.log_device_placement = True  # to log device placement (on which device the operation ran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55abc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELDNAMES = ['Model', 'Time', 'Samples', 'DDOS%', 'Accuracy', 'F1Score', 'TPR', 'FPR', 'TNR', 'FNR', 'Source']\n",
    "FEATURE_INDEX = 1 #number between 0 and 10\n",
    "\n",
    "# hyperparameters\n",
    "KERNELS=64\n",
    "BATCH_SIZE=2048\n",
    "LEARNING_RATE=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a20367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    filename = glob.glob(path)[0]\n",
    "    dataset = h5py.File(filename, \"r\")\n",
    "    set_x_orig = np.array(dataset[\"set_x\"][:])  # features\n",
    "    set_y_orig = np.array(dataset[\"set_y\"][:])  # labels\n",
    "\n",
    "    X = np.reshape(set_x_orig, (set_x_orig.shape[0], set_x_orig.shape[1], set_x_orig.shape[2], 1))\n",
    "    Y = set_y_orig\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d451046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_packet_feature(X, y, feat_index=1, pert_scale=0.01):\n",
    "    perturbed_X=[]\n",
    "    for index in range(y.shape[0]):\n",
    "        x_copy = copy.deepcopy(X[index])\n",
    "        if y[index] == 1: #we perturb only malicious samples\n",
    "            for row in x_copy:\n",
    "                if (np.sum(row) > 0): # we only perturb packets, not padded rows\n",
    "                    row[feat_index] = np.clip(row[feat_index] + normal(scale=pert_scale),0,1) # add gaussian noise and limit the value in the [0,1] range\n",
    "            xs = np.squeeze(X[index])\n",
    "            xcs = np.squeeze(x_copy)\n",
    "        perturbed_X.append(x_copy)\n",
    "    return np.array(perturbed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ab2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pdf(X,y,feat_index=1):\n",
    "    pdf = []\n",
    "    total = 0\n",
    "    for index in range(y.shape[0]):\n",
    "        x = X[index]\n",
    "        if y[index] == 1:  # we perturb only malicious samples\n",
    "            for row in x:\n",
    "                if (np.sum(row) > 0):  # we only perturb packets, not padded rows\n",
    "                    feat_value = np.asscalar(row[feat_index])\n",
    "                    pdf.append(feat_value)\n",
    "                    total += feat_value\n",
    "    n, bins, patches = plt.hist(pdf, bins=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d54ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_results(Y_true, Y_pred, model_name, data_source, prediction_time):\n",
    "    ddos_rate = '{:04.3f}'.format(sum(Y_pred) / Y_pred.shape[0])\n",
    "\n",
    "    if Y_true is not None:  # if we have the labels, we can compute the classification accuracy\n",
    "        Y_true = Y_true.reshape((Y_true.shape[0], 1))\n",
    "        accuracy = accuracy_score(Y_true, Y_pred)\n",
    "\n",
    "        f1 = f1_score(Y_true, Y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(Y_true, Y_pred, labels=[0, 1]).ravel()\n",
    "        tnr = tn / (tn + fp)\n",
    "        fpr = fp / (fp + tn)\n",
    "        fnr = fn / (fn + tp)\n",
    "        tpr = tp / (tp + fn)\n",
    "\n",
    "        row = {'Model': model_name, 'Time': '{:04.3f}'.format(prediction_time),\n",
    "               'Samples': Y_pred.shape[0], 'DDOS%': ddos_rate, 'Accuracy': accuracy, 'F1Score': f1,\n",
    "               'TPR': tpr, 'FPR': fpr, 'TNR': tnr, 'FNR': fnr, 'Source': data_source}\n",
    "    else:\n",
    "        row = {'Model': model_name, 'Time': '{:04.3f}'.format(prediction_time),\n",
    "               'Samples': Y_pred.shape[0], 'DDOS%': ddos_rate, 'Accuracy': \"N/A\", 'F1Score': \"N/A\",\n",
    "               'TPR': \"N/A\", 'FPR': \"N/A\", 'TNR': \"N/A\", 'FNR': \"N/A\", 'Source': data_source}\n",
    "    pprint.pprint(row, sort_dicts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8407d7d9",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f40c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv2DModel(kernels=KERNELS,kernel_rows=3,kernel_col=11,learning_rate=LEARNING_RATE,input_shape=(10,11,1)):\n",
    "    K.clear_session()\n",
    "\n",
    "    model = Sequential(name=\"CNN\")\n",
    "    model.add(Conv2D(kernels, (kernel_rows,kernel_col), strides=(1, 1), input_shape=input_shape, name='conv0'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(GlobalMaxPooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid', name='fc1'))\n",
    "\n",
    "    compileModel(model, learning_rate)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f60255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileModel(model,lr):\n",
    "    optimizer = Adam(learning_rate=lr, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')  # here we specify the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e7b7e1",
   "metadata": {},
   "source": [
    "## Training phase\n",
    "Here we train the neural network using a patience value of 10 epochs and a maximum numer of epochs set to 100. You can reduce the value of patience or the max number of epochs is the training process takes too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d2b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_dataset('../Datasets/IDS2017/*-train.hdf5')\n",
    "X_val, y_val = load_dataset('../Datasets/IDS2017/*-val.hdf5')\n",
    "\n",
    "cnn = Conv2DModel()\n",
    "cnn.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=100,validation_data=(X_val, y_val), callbacks=[EarlyStopping(monitor='val_loss',restore_best_weights=True, patience=10)])\n",
    "\n",
    "print(\"Saving best model's weights...\")\n",
    "cnn.save(\"./\" + cnn.name + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eecd6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = load_dataset('../Datasets/IDS2017/*-test.hdf5')\n",
    "\n",
    "model_file = glob.glob(\".\" + \"/*.h5\")[0]\n",
    "model = load_model(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78d5c0",
   "metadata": {},
   "source": [
    "## Test phase with unperturbed data\n",
    "Now we evaluate the trained model on unperturbed test data. Accuracy results are printed on the screen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0317084",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt0 = time.time()\n",
    "Y_pred = np.squeeze(model.predict(X_test, batch_size=2048) > 0.5)\n",
    "pt1 = time.time()\n",
    "report_results(Y_test, Y_pred, model.name, \"unperturbed attack traffic\", pt1 - pt0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3977223",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_perturbed = perturb_packet_feature(X_test, Y_test, FEATURE_INDEX, 0.1)\n",
    "pt0 = time.time()\n",
    "Y_pred = np.squeeze(model.predict(X_test_perturbed, batch_size=2048) > 0.5)\n",
    "pt1 = time.time()\n",
    "report_results(Y_test, Y_pred, model.name, \"perturbed feature \" + str(FEATURE_INDEX), pt1 - pt0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0302e0df",
   "metadata": {},
   "source": [
    "## Plot feature's distribution\n",
    "We can plot the pdf of the perturbed feature before and after the perturbation to understand how the feature's values have been affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce69e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pdf(X_test, Y_test, FEATURE_INDEX)\n",
    "plot_pdf(X_test_perturbed, Y_test, FEATURE_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece46001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
