{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2916704",
   "metadata": {},
   "source": [
    "# Feature importance analysis\n",
    "In this laboratory you will use two different techniques to analyse the relative importance of the dataset features. In the first part, you will use a Random Forest to evaluate the relative importance of the features of the training set. This technique is often used to get rid of irrelevant features before training. In the second step, you will use the feature elimination technique to understand which features contribute most to the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a046372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Roberto Doriguzzi-Corin\n",
    "# Project: Lecture on Intrusion Detection with Deep Learning\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import h5py\n",
    "import sys\n",
    "import copy\n",
    "import argparse\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(inter_op_parallelism_threads=1)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams.update({'figure.figsize': (12.0, 8.0)})\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "SEED=1\n",
    "feature_names = ['time','packet_len','highest_proto','IP flags','protocols','TCP len','TCP ack','TCP flags','TCP win_size',\n",
    "                         'UDP len','ICMP type','flow_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    filename = glob.glob(path)[0]\n",
    "    dataset = h5py.File(filename, \"r\")\n",
    "    set_x_orig = np.array(dataset[\"set_x\"][:])  # features\n",
    "    set_y_orig = np.array(dataset[\"set_y\"][:])  # labels\n",
    "\n",
    "    X = np.reshape(set_x_orig, (set_x_orig.shape[0], set_x_orig.shape[1], set_x_orig.shape[2], 1))\n",
    "    Y = set_y_orig\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547977d1",
   "metadata": {},
   "source": [
    "## Feature elimination\n",
    "The following method removes one feature at a time from a given sample X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2136aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_one_feature(X,index):\n",
    "    X_new = []\n",
    "    for sample in X:\n",
    "        new_sample = copy.deepcopy(sample)\n",
    "        new_sample[index] = 0\n",
    "        X_new.append(new_sample)\n",
    "    return np.array(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93677c06",
   "metadata": {},
   "source": [
    "## Reshaping the samples\n",
    "The training samples are two-dimensinal arrays of size 10x11, in which the rows are packets in chronological order (up to 10 packets) and the columns are packet-level features (11 features such as packet length, TCP flags, etc.) ([LUCID representation of the network traffic](https://github.com/doriguzzi/lucid-ddos)). The packets in a sample belong to a single traffic flow as collected within a time window of 10 seconds. If less then 10 packets are collected within a given time window, the sample is zero-padded. Therefore, the number of non-zero rows can be interpreted as an additional feature representing the number of packets collected in a time window for a specific flow.\n",
    "\n",
    "To evaluate the importance of each traffic feature with Random Forest (including the number of packets), you need first to convert a two-dimensional array into a vector of 12 elements. The first 11 elements are the average value of each packet feature, while the 12th element is the number of packets of the flow (number of non-zero rows). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595dc04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_samples(X_train):\n",
    "    X_new = []\n",
    "    for sample in X_train:\n",
    "        sample = np.squeeze(sample)\n",
    "        packets_nr = np.count_nonzero(sample.sum(axis=1)) #number of non-zero rows\n",
    "        new_sample = np.mean(sample,axis=0)  # average value of each packet feature in a sample\n",
    "        new_sample = np.append(new_sample,[packets_nr],axis=0) \n",
    "        X_new.append(new_sample)\n",
    "    return np.array(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27017f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = load_dataset(\"../Datasets/IDS2017/*\" + '-train.hdf5')\n",
    "X_train = flatten_samples(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e752454c",
   "metadata": {},
   "source": [
    "## Feature analysis with Random Forest\n",
    "Replace code in the cell below with a random forest that estimates the relative importance of each feature in the training set. In this part of the laboratory, you will use a 1D representation of the flows to understand which features are more important for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_ = np.random.rand(X_train.shape[1]) # replace with a RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f9b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(feature_names, feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bd67a0",
   "metadata": {},
   "source": [
    "## Analisys of feature importance with feature elimination\n",
    "In the cells below, the importance of each feature in the classification task is estimated by removing one feature at a time and evaluating the results on the test set with a pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae5e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = load_dataset(\"../Datasets/IDS2017/*\" + '-test.hdf5')\n",
    "X_test = flatten_samples(X_test)\n",
    "model = load_model(\"../Models/10t-1n-mlp-IDS2017.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c9f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for feature in feature_names:\n",
    "    feature_index = feature_names.index(feature)\n",
    "    X_test_one_feature = remove_one_feature(X_test,feature_index)\n",
    "    Y_pred = np.squeeze(model.predict(X_test_one_feature, batch_size=2048) > 0.5) \n",
    "    f1 = f1_score(Y_test, Y_pred)\n",
    "    results.append(1-f1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0245f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(np.array(feature_names), np.array(results))\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
